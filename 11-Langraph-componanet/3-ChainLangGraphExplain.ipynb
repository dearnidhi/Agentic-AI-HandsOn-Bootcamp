{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b862139",
   "metadata": {},
   "source": [
    "# üß© Building a Chain with LangGraph\n",
    "\n",
    "A **chain** in LangGraph is a sequence of connected AI nodes that process chat messages to create a reasoning or conversation flow. Each node can use a different AI model or tool, and all nodes share the **graph state** to maintain context.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† 4 Key Concepts\n",
    "\n",
    "### 1Ô∏è‚É£ Chat Messages\n",
    "\n",
    "These are messages exchanged in a conversation.\n",
    "\n",
    "**Types of messages:**\n",
    "\n",
    "- üßç **HumanMessage** ‚Üí From the user  \n",
    "- ü§ñ **AIMessage** ‚Üí Response from the AI  \n",
    "- ‚öôÔ∏è **SystemMessage** ‚Üí Instructions to control AI behavior  \n",
    "- üß∞ **ToolMessage** ‚Üí Output from an external tool  \n",
    "\n",
    "**Example Conversation:**\n",
    "\n",
    "```text\n",
    "Human: I want to learn coding\n",
    "AI: Which language do you want to learn?\n",
    "Human: Python\n",
    "AI: Great choice! Python is beginner-friendly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc688cc7",
   "metadata": {},
   "source": [
    "These messages are stored as a list of message objects inside the graph state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783519b0",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Chat Models\n",
    "\n",
    "Nodes in LangGraph use **LLMs** (e.g., GPT-4, Groq Gemma2-9B).\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "```python\n",
    "result = llm.invoke(messages)\n",
    "\n",
    "The model sees all previous messages\n",
    "\n",
    "Responds based on the latest human message\n",
    "\n",
    "Each node can use a different model depending on its role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a75bbd2",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Binding Tools\n",
    "\n",
    "Some queries require **external data** (weather, news, databases).\n",
    "\n",
    "- LLMs alone cannot fetch real-time info  \n",
    "- We **bind external tools/APIs** to nodes  \n",
    "\n",
    "**Example:**\n",
    "\n",
    "```text\n",
    "User: What‚Äôs today‚Äôs news?\n",
    "LLM ‚Üí News API ‚Üí gets live data ‚Üí returns summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932e8758",
   "metadata": {},
   "source": [
    "Binding tools means connecting the AI node to external capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcedc97",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Executing Tool Calls\n",
    "\n",
    "- The model decides **when** to call a tool  \n",
    "- LangGraph handles **logic & execution** automatically  \n",
    "\n",
    "**Example:**\n",
    "\n",
    "- Factual query ‚Üí triggers tool call  \n",
    "- Simple query ‚Üí AI answers directly  \n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Overall Flow of a Chain\n",
    "\n",
    "**Flow diagram:**\n",
    "\n",
    "```text\n",
    "Human Input\n",
    "      ‚Üì\n",
    "[Node 1: Chat Model]\n",
    "      ‚Üì\n",
    "[Optional Tool Call]\n",
    "      ‚Üì\n",
    "[Next Node(s)]\n",
    "      ‚Üì\n",
    "Final AI Response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44e827b",
   "metadata": {},
   "source": [
    "- Each node passes graph state (messages, results, metadata) to the next node\n",
    "- Allows step-by-step reasoning with context preserved\n",
    "- Tracks how chat messages, models, and tools interact as a single workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fced61",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b896269a",
   "metadata": {},
   "source": [
    "zy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
